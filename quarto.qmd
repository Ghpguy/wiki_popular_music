---
title: "Billboard Top Ten Analysis (1958 - 2025)"
author: "Paul Harris"
format:
  html:
    code-fold: true
    toc: true
    toc-depth: 2
    code-tools: true
    theme: cosmo
---

![](images/billboard-top-10.jpg)

# Introduction

This report analyzes the Billboard Top Ten singles dataset, exploring trends in song longevity, peak positions, artist performance, and collaboration networks over time. The analysis leverages Python, pandas, and Plotly for data visualization and lifelines for survival analysis. 

## Data Loading and Preprocessing

The data was scraped and pre-processed from [Billboard's published Top Ten singles charts](https://en.wikipedia.org/wiki/Lists_of_Billboard_Hot_100_top-ten_singles).

The data was collected using a custom Python scraper, available here: [get_data.py on GitHub](https://github.com/Ghpguy/wiki_popular_music/blob/main/utils/get_data.py).

Preprocessing steps included:
- Parsing chart dates and normalizing artist names
- Handling collaborations and featured artists
- Calculating song entry, peak, and longevity metrics
- Removing duplicates and correcting known data errors
The resulting CSV contains columns for song name, artist(s), entry/peak dates, peak position, weeks in top ten, and more.  
[View the raw CSV on GitHub](https://github.com/Ghpguy/wiki_popular_music/blob/main/data/billboard_data_2025_09.csv)

```{python}
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from lifelines import KaplanMeierFitter
from sklearn.cluster import KMeans
import networkx as nx
import calendar
from pathlib import Path
import re
import plotly.io as pio

# Use iframe renderer, which works reliably in Quarto HTML
pio.renderers.default = "iframe"

# Load data
repo_root = Path().resolve()
csv_path = repo_root / "data" / "billboard_data_2025_09.csv"
df = pd.read_csv(csv_path)
df['Top Ten Entry Date'] = pd.to_datetime(df['Top Ten Entry Date'], errors='coerce')
df['Peak Date'] = pd.to_datetime(df['Peak Date'], errors='coerce')
df['Decade'] = (df['Top Ten Entry Date'].dt.year // 10) * 10
df.head()
```

# Song Longevity in the Top Ten

How long do songs last in the Top Ten? Has it changed over time?

```{python}
print(
  f"Average weeks in Top Ten (all songs): {df['Weeks in Top Ten'].mean():.2f}"
)
print(
  "Average weeks in Top Ten by decade:\n",
  df.groupby('Decade')['Weeks in Top Ten'].mean().round(2)
)
```

## Overall Distribution

```{python}
print(f"The overall average number of weeks a song spends in the top 10 is {df['Weeks in Top Ten'].mean():.2f} weeks")
fig = px.bar(
  df['Weeks in Top Ten'].value_counts().sort_index().reset_index(),
  x='Weeks in Top Ten',
  y='count',
  text_auto=True,
  title="Overall Distribution of Weeks in Top Ten (Exact Weeks)"
)
fig.show()
```

## By Decade

It seems that by decade the general trend is that songs are lasting longer on the top ten charts. Popular sentiment finds that songs have been lasting longer on the charts, making it harder for newer songs / artists to compete in the space. 

```{python}
decade_stats = df.groupby('Decade', as_index=False)['Weeks in Top Ten'].mean()
fig = px.bar(
  decade_stats,
  x='Decade',
  y='Weeks in Top Ten',
  text_auto='.2f',
  title="Average Weeks in Top Ten by Decade"
)
fig.show()
```

## By Year

```{python}
trend = df.groupby("Year")["Weeks in Top Ten"].mean().reset_index()
fig = px.line(
  trend,
  x="Year",
  y="Weeks in Top Ten",
  title="Average Weeks in Top Ten Over Time Per Year",
  labels={"Weeks in Top Ten": "Avg Weeks", "Year": "Year"}
)
fig.show()
```

# Survival Analysis

This section applies survival analysis to the Billboard Top Ten singles dataset, using the Kaplan-Meier estimator to model the probability that a song remains in the Top Ten as weeks progress. The survival curve visualizes the likelihood of a song staying in the Top Ten over time, both for all songs and broken down by decade. This helps reveal changes in song longevity and chart dynamics across different eras.

## Survival Curve (All Songs)

```{python}
kmf = KaplanMeierFitter()
kmf.fit(df["Weeks in Top Ten"], event_observed=[1]*len(df))
survival_df = kmf.survival_function_.reset_index()
survival_df.columns = ["Weeks in Top Ten", "Probability of Staying"]
fig = px.line(
  survival_df,
  x="Weeks in Top Ten",
  y="Probability of Staying",
  title="Survival Curve of Billboard Top Ten Singles",
  labels={"Weeks in Top Ten": "Weeks in Top Ten", "Probability of Staying": "Probability of Staying in Top Ten"}
)
fig.show()
```

## Survival Curves by Decade

```{python}
fig = go.Figure()
kmf = KaplanMeierFitter()

# Only unique decades
decades = sorted(df['Decade'].dropna().unique())

for i, decade in enumerate(decades):
    group = df[df['Decade'] == decade]
    if len(group) == 0:
        continue

    # Fit Kaplan-Meier curve
    kmf.fit(group["Weeks in Top Ten"], event_observed=[1]*len(group))
    surv = kmf.survival_function_.reset_index()
    surv.columns = ["Weeks in Top Ten", "Probability of Staying"]

    # Add survival curve
    fig.add_trace(
        go.Scatter(
            x=surv["Weeks in Top Ten"],
            y=surv["Probability of Staying"],
            mode="lines",
            name=str(decade),
            line=dict(width=3)
        )
    )

    # Automatically pick evenly spaced points along the middle 80% of the curve
    n_labels = 1
    start_idx = int(len(surv) * 0.3)   # skip first 10%
    end_idx = int(len(surv) * 0.95)     # skip last 10%
    indices = np.linspace(start_idx, end_idx, n_labels, dtype=int)

    for j, idx in enumerate(indices):
        # stagger labels vertically to reduce overlap
        y_offset = 15 * (i - len(decades)/2) + 10 * (j - (n_labels-1)/2)

        # Add annotation once per point
        fig.add_annotation(
            x=surv["Weeks in Top Ten"].iloc[idx],
            y=surv["Probability of Staying"].iloc[idx],
            text=f"{decade}",
            showarrow=True,
            arrowhead=2,
            font=dict(size=12),
            ax=0,
            ay=-y_offset
        )

# Layout
fig.update_layout(
    title="Survival Curves of Billboard Top Ten Singles by Decade",
    xaxis_title="Weeks in Top Ten",
    yaxis_title="Probability of Staying in Top Ten",
    yaxis=dict(range=[0, 1]),
    showlegend=True
)

fig.show()
```


# Peak Positions

This section explores the distribution and trends of peak chart positions for songs in the Billboard Top Ten. It examines how often songs reach each peak position, and analyzes changes in average peak positions over decades and years. The visualizations help reveal whether songs are more likely to reach higher or lower peaks over time, and provide insight into the competitiveness of the charts across different eras. Overall it seems that peak position competitiveness remains mostly similar.

## Distribution of Peak Positions

```{python}
fig = px.bar(
  df['Peak'].value_counts().sort_index().reset_index(),
  x='Peak',
  y='count',
  text_auto=True,
  title="Overall Distribution of Peak Positions"
)
fig.show()
```

## Average Peak by Decade

```{python}
decade_stats = df.groupby('Decade', as_index=False)['Peak'].mean()
fig = px.bar(
  decade_stats,
  x='Decade',
  y='Peak',
  text_auto='.2f',
  title="Average Peak Position in Top Ten by Decade"
)
fig.show()
```

## Average Peak by Year

```{python}
trend = df.groupby("Year")["Peak"].mean().reset_index()
fig = px.line(
  trend,
  x="Year",
  y="Peak",
  title="Average Peak Position in Top Ten Over Time Per Year",
  labels={"Peak": "Avg Peak Position", "Year": "Year"}
)
fig.show()
```

# Longevity by Peak Position

This section examines how the longevity of a song in the Top Ten relates to its peak chart position. By analyzing the average number of weeks songs spend in the Top Ten for each peak position (from #1 to #10), we can see whether songs that reach higher peaks tend to have longer or shorter chart runs. This helps reveal if top-performing songs dominate the charts for longer periods, or if lower-peaking songs can also achieve significant longevity.

```{python}
longevity_by_peak = df.groupby("Peak")["Weeks in Top Ten"].mean().reset_index()
longevity_by_peak = longevity_by_peak.sort_values("Peak")
longevity_by_peak["Weeks in Top Ten"] = longevity_by_peak["Weeks in Top Ten"].round(1)
fig = px.bar(
  longevity_by_peak,
  x="Peak",
  y="Weeks in Top Ten",
  text="Weeks in Top Ten",
  labels={"Peak": "Peak Position", "Weeks in Top Ten": "Avg Weeks"},
  title="Average Weeks in Top Ten by Peak Position"
)
fig.show()
```

# Number of Entries per Year

This supplemental chart demonstarates the result of songs living longer in the top ten - as a result we are seeing less entries breaking into the top ten and removing older top ten hits.

```{python}
entries_per_year = df.groupby("Year")["Single Name"].count().reset_index()
entries_per_year.rename(columns={"Single Name": "Count"}, inplace=True)
fig = px.line(
  entries_per_year,
  x="Year",
  y="Count",
  title="Number of Top Ten Entries per Year",
  labels={"Year": "Year", "Count": "Number of Entries"}
)
fig.show()
```

# Top Artists and One-Hit Wonders

So which artists are we seeing occupy the most real estate on the charts?

## Top 10 Artists by Top Ten Entries

```{python}
top_artists = df["Artist(s)"].value_counts().reset_index()
top_artists.columns = ["Artist", "Entries"]
top_artists = top_artists.sort_values("Entries", ascending=False).head(10)
fig = px.bar(
  top_artists,
  x="Entries",
  y="Artist",
  orientation="h",
  text="Entries",
  title="Top Artists by Top Ten Entries"
)
fig.show()
```

## Top 10 Artists by Top Ten Real Estate

This chart shows the top artists by the total amount of weekly space they have occupied on the top ten charts 

```{python}
# Calculate total weeks in Top Ten for each artist
artist_real_estate = df.groupby("Artist(s)")["Weeks in Top Ten"].sum().reset_index()
artist_real_estate = artist_real_estate.sort_values("Weeks in Top Ten", ascending=False).head(10)

# Plot horizontal bar chart
fig = px.bar(
    artist_real_estate,
    x="Weeks in Top Ten",
    y="Artist(s)",
    orientation="h",
    text="Weeks in Top Ten",
    title="Top 10 Artists by Total Weeks in Top Ten (Chart Real Estate)"
)

fig.update_traces(textposition="outside")
fig.update_layout(
    xaxis_title="Total Weeks in Top Ten",
    yaxis_title="Artist",
    yaxis=dict(autorange="reversed")
)

fig.show()
```

## One-Hit Wonders

Which artists make one entry on the top ten charts but never return?

```{python}
artist_song_counts = df.groupby("Artist(s)")["Single Name"].nunique()
one_hit_pct = (artist_song_counts == 1).mean() * 100
print(f"One-hit wonders (Artists that reach the top 10 only once): {one_hit_pct:.1f}% of artists")
```

# Seasonality: Top Ten Entries by Month and Decade

Do more songs enter the top ten during certain months compared to other months? (Holiday Songs Excluded) 

```{python}
df['Month'] = df['Top Ten Entry Date'].dt.month
entries_by_month_decade = df.groupby(['Month', 'Decade'])['Single Name'].count().reset_index()
entries_by_month_decade.rename(columns={"Single Name": "Entries"}, inplace=True)
entries_by_month_decade['Month Name'] = entries_by_month_decade['Month'].apply(lambda x: calendar.month_abbr[x])
fig = px.bar(
  entries_by_month_decade,
  x='Month Name',
  y='Entries',
  color='Decade',
  barmode='group',
  text='Entries',
  title='Top Ten Entries by Month and Decade',
  height=700
)
fig.show()
```

# Song Trajectory: Lag to Peak

The "Lag to Peak" metric measures the number of days between a song's entry into the Top Ten and the date it reaches its highest chart position. This helps identify songs that quickly shoot to their peak versus those that climb more gradually—so-called "sleeper hits." The distribution below shows that while many songs reach their peak soon after entering the Top Ten, a notable subset takes several weeks or even months to peak, reflecting different promotional strategies, viral trends, or seasonal effects.

```{python}
df["Lag to Peak"] = (df["Peak Date"] - df["Top Ten Entry Date"]).dt.days
lag_data = df["Lag to Peak"].dropna()
fig = px.histogram(
  lag_data,
  nbins=30,
  title="Distribution of Days to Peak Position",
  labels={"value": "Days", "count": "Count"}
)
fig.show()
```

## Top 10 Songs with Greatest Lag to Peak

```{python}
top_lag = df.nlargest(10, "Lag to Peak")[["Single Name", "Artist(s)", "Lag to Peak", "Top Ten Entry Date", "Peak Date"]]
top_lag['Label'] = top_lag["Single Name"] + " – " + top_lag["Artist(s)"]
fig_top_lag = px.bar(
  top_lag,
  x="Lag to Peak",
  y="Label",
  orientation='h',
  text="Lag to Peak",
  hover_data={
    "Lag to Peak": True,
    "Top Ten Entry Date": True,
    "Peak Date": True,
    "Label": False
  },
  title="Top 10 Songs with Greatest Lag to Peak"
)
fig_top_lag.show()
```

# Longest-Running Top Ten Songs

```{python}
longest = df.nlargest(20, "Weeks in Top Ten")[["Single Name", "Artist(s)", "Weeks in Top Ten"]]
longest['Label'] = longest["Single Name"] + " – " + longest["Artist(s)"]
fig_longest = px.bar(
  longest,
  x="Weeks in Top Ten",
  y="Label",
  orientation='h',
  text="Weeks in Top Ten",
  title="Top 20 Longest-Running Top Ten Songs"
)
fig_longest.show()
```

# Clustering Song Trajectories

This section uses K-means clustering to group songs based on their chart trajectory characteristics: "Lag to Peak" (how long it took to reach peak position), "Weeks in Top Ten" (overall longevity), and "Peak" (best chart position). By visualizing these clusters, we can identify distinct types of hits, such as instant chart-toppers, slow-burn "sleeper hits," and songs with brief or moderate success. The scatter plot below shows each song colored by its assigned cluster, helping to reveal patterns in how songs move through the Top Ten.

```{python}
def clustering_plotly(df, k=4):
  features = df[["Lag to Peak", "Weeks in Top Ten", "Peak"]].dropna()
  km = KMeans(n_clusters=k, random_state=42, n_init=10).fit(features)
  df.loc[features.index, "Cluster"] = km.labels_.astype(str)
  fig_scatter = px.scatter(
    df.loc[features.index],
    x="Lag to Peak",
    y="Weeks in Top Ten",
    color="Cluster",
    hover_data=["Peak", "Lag to Peak", "Weeks in Top Ten", "Single Name", "Artist(s)"],
    title="K-means Clustering of Songs",
    height=600
  )
  fig_scatter.show()
clustering_plotly(df, k=4)
```

## Sleeper Hits (Cluster 2)

```{python}
cluster_2_songs = df[df["Cluster"] == "2"][["Single Name", "Artist(s)", "Weeks in Top Ten", "Lag to Peak", "Peak"]]
cluster_2_songs_sorted = cluster_2_songs.sort_values(by=["Peak", "Weeks in Top Ten"], ascending=[True, False])
cluster_2_songs_sorted['Label'] = cluster_2_songs_sorted["Single Name"] + " – " + cluster_2_songs_sorted["Artist(s)"]
fig_cluster2 = px.bar(
  cluster_2_songs_sorted,
  x="Weeks in Top Ten",
  y="Label",
  orientation='h',
  text="Weeks in Top Ten",
  hover_data=["Peak", "Lag to Peak"],
  title="Sleeper Hits (Songs that Peaked Late but Stayed Long)",
  height=800
)
fig_cluster2.show()
```

# Artist Collaboration Networks by Decade

This section visualizes how artists collaborate within each decade, revealing the most central figures in the collaboration network for each era. For every decade, a network graph is constructed where nodes represent artists and edges indicate collaborations (including features and joint credits). The top 10 most connected artists (by degree centrality) are highlighted, and their collaboration networks are visualized using interactive network diagrams. This helps illustrate how collaboration patterns and key influencers have evolved across decades in popular music.

```{python}
frames = []
decade_list = sorted(df['Decade'].dropna().unique())
for decade in decade_list:
  group = df[df['Decade'] == decade]
  G = nx.Graph()
  for artists in group["Artist(s)"].dropna():
    cleaned = re.sub(
      r'\s*(?:&|\bfeat\.?\b|\bfeaturing\b|,|\band\b|\&)\s*',
      ',',
      str(artists),
      flags=re.IGNORECASE
    )
    names = [a.strip() for a in cleaned.split(',') if a.strip()]
    for i in range(len(names)):
      for j in range(i+1, len(names)):
        G.add_edge(names[i], names[j])
  deg = nx.degree_centrality(G)
  top_artists = sorted(deg.items(), key=lambda x: x[1], reverse=True)[:10]
  subG = G.subgraph(dict(top_artists).keys())
  pos = nx.spring_layout(subG, seed=42)
  edge_x, edge_y = [], []
  for edge in subG.edges():
    x0, y0 = pos[edge[0]]
    x1, y1 = pos[edge[1]]
    edge_x += [x0, x1, None]
    edge_y += [y0, y1, None]
  edge_trace = go.Scatter(
    x=edge_x, y=edge_y,
    line=dict(width=1, color='#888'),
    hoverinfo='none',
    mode='lines'
  )
  node_x, node_y, node_text, node_size = [], [], [], []
  for node in subG.nodes():
    x, y = pos[node]
    node_x.append(x)
    node_y.append(y)
    node_text.append(node)
    node_size.append(deg[node]*2000)
  node_trace = go.Scatter(
    x=node_x, y=node_y,
    mode='markers+text',
    hovertext=node_text,
    text=node_text,
    textposition='top center',
    marker=dict(size=node_size, color='lightblue'),
    showlegend=False
  )
  frames.append(go.Frame(data=[edge_trace, node_trace], name=str(decade)))
# Initial figure
fig = go.Figure(
  data=frames[0].data,
  layout=go.Layout(
    title="Top Artist Collaboration Network by Decade",
    width=1000,
    height=1000,
    xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
    yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
    showlegend=False
  ),
  frames=frames
)
fig.show()
```

# Conclusion

This analysis provides a comprehensive overview of trends in the Billboard Top Ten, including song longevity, peak positions, artist performance, and collaboration networks. Further exploration could include genre-based analysis, deeper clustering, tests for statistical significance, or predictive modeling.

![](images/music.gif)


---
